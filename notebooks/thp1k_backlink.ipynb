{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1376422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "\n",
    "##Configurable Items\n",
    "api_key_file = 'G:/My Drive/Lindsay Pino/proj/2023_scispot_utils/data/scispot_api_key.txt'\n",
    "API_TOKEN = open(api_key_file, 'r').readlines()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e20abaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e8cb1f7c-0799-475e-8b8e-83170db0cbcf'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch a Scispot entry based on the Sample ID\n",
    "def fetch_entry_from_registryid(manager, registryid):\n",
    "    # strip prefix from registry id\n",
    "    \n",
    "    registryid = re.sub(\"[^0-9]\", \"\", registryid)\n",
    "    \n",
    "    session = requests.Session()\n",
    "    url = \"https://api.scispot.io/tryingtofixcors/labsheets/find-row-by-id\"\n",
    "    payload = {\n",
    "        \"apiKey\": API_TOKEN,\n",
    "        \"labsheet\": manager,\n",
    "        \"id\": registryid,  #  value for \"id\" key should exclude the prefix and suffix \n",
    "        \"idType\": \"ID_BARCODE\"\n",
    "    }\n",
    "    ret = session.post(url, json=payload)\n",
    "    return json.loads(ret.text)\n",
    "\n",
    "def grab_uuid_from_row(row):\n",
    "    return row['rows'][0][0]\n",
    "\n",
    "# lookup test_digest in Labsheets\n",
    "test_digest = \"PDG97\"  # peptides that ran for MSR97\n",
    "\n",
    "test_fetch_uuid = grab_uuid_from_row(fetch_entry_from_registryid(\"Peptide Digest\", test_digest))\n",
    "test_fetch_uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1664c836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4ab8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f44f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a7db38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e862defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "\n",
    "PROD_URL = \"https://api.scispot.io/v2\"\n",
    "\n",
    "\n",
    "class APIException(Exception):\n",
    "    def __init__(self, message, endpoint, payload, res):\n",
    "        self.message = message + \"\\n\"\n",
    "        self.message += \"Request: \" + endpoint + \"\\n\"\n",
    "        annonimized_payload = {\n",
    "            k: v if \"api\" not in k else \"*\" * len(v)\n",
    "            for k, v in payload.items()\n",
    "        }\n",
    "        self.message += str(json.dumps(annonimized_payload, indent=2)) + \"\\n\"\n",
    "        self.message += \"Response: \" + str(json.dumps(res, indent=2)) + \"\\n\"\n",
    "        super().__init__(self.message)\n",
    "\n",
    "\n",
    "class Labsheet:\n",
    "    ADD_ROWS = \"/labsheets/add-rows\"\n",
    "    UPDATE_ROWS = \"/labsheets/update-rows\"\n",
    "    UPDATE_ROWS_BY_ID = \"/labsheets/update-rows-by-id\"\n",
    "    UPDATE_ROWS_BY_COLTYPE = \"/labsheets/update-rows-by-column-type\"\n",
    "    FIND_ROW = \"/labsheets/find-row\"\n",
    "    FIND_ROW_BY_ID = \"/labsheets/find-row-by-id\"\n",
    "    LIST_ROWS = \"/labsheets/list-rows\"\n",
    "    DELETE_ROWS = \"/labsheets/delete-rows\"\n",
    "    CREATE = \"/labsheets/create\"\n",
    "    UPDATE_PARENT = \"/labsheets/update-parent\"\n",
    "    UPDATE_CHILDREN = \"/labsheets/update-children\"\n",
    "\n",
    "    def __init__(self, name, api_key, verbose=False, base=\"dev\"):\n",
    "        self.name = name\n",
    "        self.api_key = api_key\n",
    "        self.verbose = verbose\n",
    "        if base == \"prod\":\n",
    "            self.BASE_URL = PROD_URL\n",
    "        else:\n",
    "            raise APIException(\"Incorrect base. Must be 'prod'\")\n",
    "\n",
    "    ## Supports limited column types.\n",
    "    ## Q: What are the non supported column types? - JSP\n",
    "    def create(self, header_names, header_types):\n",
    "        \"\"\"Creates a labsheet.\"\"\"\n",
    "        columns = []\n",
    "        for i in range(len(header_names)):\n",
    "            columns.append(\n",
    "                {\n",
    "                    \"position\": i,\n",
    "                    \"name\": header_names[i],\n",
    "                    \"type\": header_types[i],\n",
    "                }\n",
    "            )\n",
    "        payload = {\"name\": self.name, \"columns\": columns}\n",
    "        res = self.make_request(self.CREATE, payload)\n",
    "        self.error_check(res, payload, self.CREATE)\n",
    "        print(\"successfully created labsheet.\")\n",
    "        return res\n",
    "\n",
    "    def make_request(self, endpoint, payload):\n",
    "        \"\"\"Makes a request to the API.\n",
    "\n",
    "        This is meant to be internal, for most cases you should use the\n",
    "        other methods (e.g. add_rows, update_rows, etc).\n",
    "        \"\"\"\n",
    "        payload[\"apiKey\"] = self.api_key\n",
    "        payload[\"manager\"] = self.name\n",
    "        payload[\"labsheet\"] = self.name\n",
    "        if self.verbose:\n",
    "            print(self.BASE_URL + endpoint)\n",
    "            # This will print the api key in plaintext...\n",
    "            # which is a security vulnerability ... so lets not do that ...\n",
    "            # print(str(json.dumps(payload, indent=4)))\n",
    "            public_payload = {\n",
    "                k: \"*\" * len(v) if \"api\" in k else v\n",
    "                for k, v in payload.items()\n",
    "            }\n",
    "\n",
    "            print(str(json.dumps(public_payload, indent=4)))\n",
    "        req = requests.post(url=self.BASE_URL + endpoint, json=payload)\n",
    "        res = json.loads(req.text)\n",
    "        return res\n",
    "\n",
    "    def error_check(self, res, payload, endpoint) -> None:\n",
    "        \"\"\"Checks for errors in the response.\n",
    "\n",
    "        It reads the response and raises a python error if an API\n",
    "        error is detected.\n",
    "        \"\"\"\n",
    "        if isinstance(res, dict):\n",
    "            if \"success\" not in res:\n",
    "                raise APIException(\n",
    "                    \"An error occured: \", endpoint, payload, res\n",
    "                )\n",
    "\n",
    "            # When would this happen?\n",
    "            # why is this not consistent?\n",
    "            if res[\"success\"] == \"false\" or not res[\"success\"]:\n",
    "                raise APIException(\n",
    "                    \"An error occured: \", endpoint, payload, res\n",
    "                )\n",
    "        elif isinstance(res, list):\n",
    "            \"\"\"\n",
    "            Example response from the update_rows endpoint:\n",
    "            [\n",
    "            {\n",
    "                \"ID\": \"98\",\n",
    "                \"updatedRows\": [\n",
    "                {\n",
    "                    \"uuid\": \"50738ad7-c7e0-44da-9a29-3c0dec898075\",\n",
    "                    \"success\": \"true\"\n",
    "                }\n",
    "                ]\n",
    "            }\n",
    "            ]\n",
    "            \"\"\"\n",
    "            for row in res:\n",
    "                if \"updatedRows\" in row:\n",
    "                    for updated_row in row[\"updatedRows\"]:\n",
    "                        if \"success\" not in updated_row:\n",
    "                            raise APIException(\n",
    "                                \"An error occured: \", endpoint, payload, res\n",
    "                            )\n",
    "\n",
    "                        if (\n",
    "                            updated_row[\"success\"] == \"false\"\n",
    "                            or not updated_row[\"success\"]\n",
    "                        ):\n",
    "                            raise APIException(\n",
    "                                \"An error occured: \",\n",
    "                                endpoint,\n",
    "                                payload,\n",
    "                                res,\n",
    "                            )\n",
    "                    return\n",
    "\n",
    "                if \"success\" not in row:\n",
    "                    raise APIException(\n",
    "                        \"An error occured: \", endpoint, payload, res\n",
    "                    )\n",
    "\n",
    "                if row[\"success\"] == \"false\" or not row[\"success\"]:\n",
    "                    raise APIException(\n",
    "                        \"An error occured: \", endpoint, payload, res\n",
    "                    )\n",
    "\n",
    "    def add_rows(self, rows: List[List[str]]):\n",
    "        \"\"\"Adds rows to the table (labsheet).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rows : list of lists\n",
    "            List of rows to add. Each row is a list of values.\n",
    "            For example:\n",
    "            --data '{\n",
    "                \"apiKey\": \"12345678-abcd-9012-efgh-345678901234\",\n",
    "                \"manager\": \"Elisa Data\",\n",
    "                \"rows\": [\n",
    "                    [\n",
    "                        \"ID-15\",\n",
    "                        \"Standard\",\n",
    "                        \"50mL\",\n",
    "                        \"A\",\n",
    "                        \"09/03/2022\",\n",
    "                        \"Hazardous\",\n",
    "                        \"Unknown\",\n",
    "                        \"North Lab > Well Plate 23\",\n",
    "                        \"134-amf\"\n",
    "                    ]\n",
    "                ]}'\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        The column order is determined by the order of the columns in the labsheet.\n",
    "        Which can be queried using the get_headers()[\"headers\"] method.\n",
    "        Having said that there are some oddities with the API, where the first column\n",
    "        is skipped (thus not passed when adding rows), I am not sure what other columns\n",
    "        are generated.\n",
    "        \"\"\"\n",
    "        payload = {\"rows\": rows}\n",
    "        res = self.make_request(self.ADD_ROWS, payload)\n",
    "        print(res)\n",
    "        self.error_check(res, payload, self.ADD_ROWS)\n",
    "        print(\"successfully added rows.\")\n",
    "        return [row[\"uuid\"] for row in sorted(res, key=lambda x: x[\"row\"])]\n",
    "\n",
    "    def get_headers(self) -> List[str]:\n",
    "        \"\"\"Returns the headers of the labsheet.\"\"\"\n",
    "        res = self.list_rows(0, 0)\n",
    "        return res[\"headers\"]\n",
    "\n",
    "    # Usually, the uuid, stays packaged with the rest of the rows\n",
    "    def update_rows(self, rows):\n",
    "        payload = {\"rows\": [{\"uuid\": row[0], \"data\": row[1:]} for row in rows]}\n",
    "        res = self.make_request(self.UPDATE_ROWS, payload)\n",
    "        self.error_check(res, payload, self.UPDATE_ROWS)\n",
    "        print(\"successfully updated rows.\")\n",
    "        return res\n",
    "\n",
    "    def update_rows_by_id(self, rows: List[dict]):\n",
    "        \"\"\"Updates rows by id.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rows : list of dicts\n",
    "            List of rows to update. Each row is a dict of values.\n",
    "            For example (from the scispot docs):\n",
    "            [{}, {\"ID\": \"20c20\", \"Quantity\": \"78\", \"Comp\": \"c24\"}]\n",
    "\n",
    "        Notes from the docs\n",
    "        -------------------\n",
    "        curl --location 'https://api.scispot.io/v2/labsheets/update-rows-by-id' \\\n",
    "            --header 'Content-Type: application/json' \\\n",
    "            --data '{\n",
    "            \"apiKey\": \"12345678-abcd-9012-efgh-345678901234\",\n",
    "            \"manager\": \"Materials Manager\",\n",
    "            \"rows\": [\n",
    "                {\n",
    "                \"ID\": \"20c20\",\n",
    "                \"Quantity\": \"78\",\n",
    "                \"Comp\": \"c24\"\n",
    "                }\n",
    "            ]\n",
    "            }'\n",
    "        \"\"\"\n",
    "        payload = {\"rows\": rows}; print(payload)\n",
    "        res = self.make_request(self.UPDATE_ROWS_BY_ID, payload)\n",
    "        self.error_check(res, payload, self.UPDATE_ROWS_BY_ID)\n",
    "        print(\"successfully updated rows.\")\n",
    "        return res\n",
    "    \n",
    "    def update_rows_by_coltype(self, rows: List[dict]):\n",
    "        \"\"\"Update Row Data By Known Cell Value.\n",
    "        Note: This feature is currently only supported for BATCH_ID column type.\n",
    "        Would be cooler if it was supported for REGISTRY_ID :,)\n",
    "        \"\"\"\n",
    "        payload = {\"rows\": rows}; print(payload)\n",
    "        res = self.make_request(self.UPDATE_ROWS_BY_COLTYPE, payload)\n",
    "        self.error_check(res, payload, self.UPDATE_ROWS_BY_COLTYPE)\n",
    "        print(\"successfully updated rows.\")\n",
    "        return res\n",
    "\n",
    "    def find_row(self, id, id_type: Literal[\"uuid\", \"id\", \"barcode\"] = \"uuid\"):\n",
    "        \"\"\"Finds a row by id.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> ls.find_row(\"b543a089-dee2-42f0-a750-91effe49841c\", id_type=\"uuid\")\n",
    "        {\"headers\": [...], \"row\": [...], \"success\": \"true\"}\n",
    "        >>> ls.find_row(\"1102\", id_type=\"barcode\")\n",
    "        {\"rows\": [[...]], \"headers\": [...], \"success\": True}\n",
    "        # Note that the response from uuid is a single list,\n",
    "        # whilst the response from barcode is a list of lists.\n",
    "        \"\"\"\n",
    "        if id_type == \"uuid\":\n",
    "            payload = {\"uuid\": id}\n",
    "            res = self.make_request(self.FIND_ROW, payload)\n",
    "            self.error_check(res, payload, self.FIND_ROW)\n",
    "            print(\"successfully found row.\")\n",
    "            return res\n",
    "        elif id_type == \"id\":\n",
    "            payload = {\"id\": id}\n",
    "        elif id_type == \"barcode\":\n",
    "            payload = {\"id\": id, \"idType\": \"ID_BARCODE\"}\n",
    "        else:\n",
    "            raise APIException(\n",
    "                \"Incorrect ID type. Must be 'id', 'barcode', 'uuid'\"\n",
    "            )\n",
    "        res = self.make_request(self.FIND_ROW_BY_ID, payload)\n",
    "        self.error_check(res, payload, self.FIND_ROW)\n",
    "        print(\"successfully found row.\")\n",
    "        return res\n",
    "\n",
    "    def list_rows(self, pageSize, page=1):\n",
    "        # Q: What is the max page size? - JSP\n",
    "        payload = {\"pageSize\": pageSize, \"page\": page}\n",
    "        res = self.make_request(self.LIST_ROWS, payload)\n",
    "        self.error_check(res, payload, self.LIST_ROWS)\n",
    "        print(\"successfully listed rows.\")\n",
    "        return res\n",
    "\n",
    "    def delete_rows(self, uuids):\n",
    "        payload = {\"uuids\": uuids}\n",
    "        res = self.make_request(self.DELETE_ROWS, payload)\n",
    "        self.error_check(res, payload, self.DELETE_ROWS)\n",
    "\n",
    "    # Supports the common operation of fetching for a certain row, applying some operations, and returning it.\n",
    "    def find_then_update(self, callback, id, id_type=\"uuid\"):\n",
    "        data = self.find_row(id, id_type)\n",
    "        ret = callback(data)\n",
    "        self.update_rows(ret)\n",
    "\n",
    "    ##ONLY BARCODES FOR NOW\n",
    "    def update_parent(self, child_id, parent_id, parent_labsheet):\n",
    "        payload = {\n",
    "            \"rows\": {\n",
    "                \"barcode\": child_id,\n",
    "                \"parent\": {\"labsheet\": parent_labsheet, \"barcode\": parent_id},\n",
    "            }\n",
    "        }\n",
    "        res = self.make_request(self.UPDATE_PARENT, payload)\n",
    "        self.error_check(res, payload, self.UPDATE_PARENT)\n",
    "        print(\"successfully updated parent.\")\n",
    "\n",
    "    def create_children(self, parent_barcode, child_ids):\n",
    "        payload = {\n",
    "            \"idType\": \"ID_BARCODE\",\n",
    "            \"parent\": parent_barcode,\n",
    "            \"children\": [{\"ID\": child, \"quantity\": 0} for child in child_ids],\n",
    "        }\n",
    "        res = self.make_request(self.UPDATE_CHILDREN, payload)\n",
    "        self.error_check(res, payload, self.UPDATE_CHILDREN)\n",
    "        print(\"successfully created children.\")\n",
    "\n",
    "\n",
    "# Give mapping of parent to children barcodes\n",
    "def create_parent_child(mapping, parent_sheet, child_sheet):\n",
    "    update_parent_rows = []\n",
    "    update_child_rows = []\n",
    "    for parent in mapping:\n",
    "        children = mapping[parent]\n",
    "        for child in children:\n",
    "            update_parent_rows.append(\n",
    "                {\n",
    "                    \"barcode\": child,\n",
    "                    \"parent\": {\n",
    "                        \"labsheet\": parent_sheet.name,\n",
    "                        \"barcode\": parent,\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "        update_child_rows.append(\n",
    "            {\n",
    "                \"barcode\": parent,\n",
    "                \"children\": [\n",
    "                    {\"labsheet\": child_sheet.name, \"barcode\": child}\n",
    "                    for child in children\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "    res1 = parent_sheet.make_request(\n",
    "        parent_sheet.UPDATE_CHILDREN, {\"rows\": update_child_rows}\n",
    "    )\n",
    "    time.sleep(1)\n",
    "    res2 = child_sheet.make_request(\n",
    "        parent_sheet.UPDATE_PARENT, {\"rows\": update_parent_rows}\n",
    "    )\n",
    "    parent_sheet.error_check(\n",
    "        res1, {\"rows\": update_child_rows}, parent_sheet.UPDATE_PARENT\n",
    "    )\n",
    "    child_sheet.error_check(\n",
    "        res2, {\"rows\": update_parent_rows}, child_sheet.UPDATE_CHILDREN\n",
    "    )\n",
    "\n",
    "\n",
    "def find_values_by_header(res, header):\n",
    "    if \"rows\" in res and \"headers\" in res:\n",
    "        values = []\n",
    "        for row in res[\"rows\"]:\n",
    "            values.append(row[res[\"headers\"].index(header)])\n",
    "        return values\n",
    "    else:\n",
    "        raise APIException(\n",
    "            \"Incorrect response format. Must have 'rows' and 'headers' keys.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def array_to_dict(header, data):\n",
    "    return dict(zip(header, data))\n",
    "\n",
    "\n",
    "def dict_to_array(data):\n",
    "    if type(data) is list:\n",
    "        return {\n",
    "            \"headers\": list(data[0].keys()),\n",
    "            \"rows\": [list(row.values()) for row in data],\n",
    "        }\n",
    "    return {\"headers\": list(data.keys()), \"rows\": list(data.values())}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "771fc2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.wrapper import Labsheet\n",
    "#from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# File in the same directory as this notebook\n",
    "# notebooks/.testenv.env\n",
    "# content is like:\n",
    "# SCISPOT_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "#load_dotenv(\"./.testenv.env\")\n",
    "\n",
    "ls_msr = Labsheet(\n",
    "    name=\"MS Run\",\n",
    "    api_key=API_TOKEN,\n",
    "    verbose=False,\n",
    "    base=\"prod\",\n",
    ")\n",
    "\n",
    "ls_msc = Labsheet(\n",
    "    name=\"MS Column\",\n",
    "    api_key=API_TOKEN,\n",
    "    verbose=False,\n",
    "    base=\"prod\",\n",
    ")\n",
    "\n",
    "ls_pdg = Labsheet(\n",
    "    name=\"Peptide Digest\",\n",
    "    api_key=API_TOKEN,\n",
    "    verbose=False,\n",
    "    base=\"prod\",\n",
    ")\n",
    "\n",
    "ls_fra = Labsheet(\n",
    "    name=\"Cell Fraction\",\n",
    "    api_key=API_TOKEN,\n",
    "    verbose=False,\n",
    "    base=\"prod\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd6b9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully found row.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['5b52caf0-7c3f-46cf-9977-535c75da78dc',\n",
       "  'MSR374',\n",
       "  'SET4REP1A4_TAL0000517',\n",
       "  '10/12/2023',\n",
       "  'Daniele Canzani',\n",
       "  'DDA',\n",
       "  '44',\n",
       "  '',\n",
       "  'Evosep',\n",
       "  'S2',\n",
       "  '',\n",
       "  '',\n",
       "  '100',\n",
       "  'ng',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '420604005932',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_msr.find_row(\"374\", id_type=\"barcode\")[\"rows\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a4fac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully found row.\n",
      "successfully found row.\n",
      ">>> Found column uuid => e03cfa54-0e6a-4280-83cc-5d6797d8d6dc\n",
      ">>> Found mass spec Run Name => SET4REP1A4_TAL0000517\n",
      "{'rows': [{'Run Name': 'SET4REP1A4_TAL0000517', 'Column ID': 'e03cfa54-0e6a-4280-83cc-5d6797d8d6dc'}]}\n"
     ]
    },
    {
     "ename": "APIException",
     "evalue": "An error occured: \nRequest: /labsheets/update-rows-by-id\n{\n  \"rows\": [\n    {\n      \"Run Name\": \"SET4REP1A4_TAL0000517\",\n      \"Column ID\": \"e03cfa54-0e6a-4280-83cc-5d6797d8d6dc\"\n    }\n  ],\n  \"apiKey\": \"************************************\",\n  \"manager\": \"MS Run\",\n  \"labsheet\": \"MS Run\"\n}\nResponse: [\n  {\n    \"ID\": \"SET4REP1A4_TAL0000517\",\n    \"updatedRows\": [\n      {\n        \"uuid\": \"99808d08-cbcc-4a28-bee4-914f646b775e\",\n        \"success\": \"true\"\n      },\n      {\n        \"uuid\": \"5b52caf0-7c3f-46cf-9977-535c75da78dc\",\n        \"success\": \"false\",\n        \"message\": \"the option 04398e98-8483-4695-8a0e-48b3ccadc84d is invalid\"\n      },\n      {\n        \"uuid\": \"d3603318-7e08-4825-b61d-471c547cd1de\",\n        \"success\": \"true\"\n      }\n    ]\n  }\n]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIException\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>> Found column uuid => \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_uuid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>> Found mass spec Run Name => \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmass_spec_run_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m res \u001b[38;5;241m=\u001b[39m ls_msr\u001b[38;5;241m.\u001b[39mupdate_rows_by_id(\n\u001b[0;32m     12\u001b[0m     rows\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     13\u001b[0m         {\n\u001b[0;32m     14\u001b[0m             \u001b[38;5;66;03m#\"Registry ID\": msr,\u001b[39;00m\n\u001b[0;32m     15\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun Name\u001b[39m\u001b[38;5;124m\"\u001b[39m: mass_spec_run_name,\n\u001b[0;32m     16\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn ID\u001b[39m\u001b[38;5;124m\"\u001b[39m: column_uuid,\n\u001b[0;32m     17\u001b[0m         }\n\u001b[0;32m     18\u001b[0m     ]\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdated MSR -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with column -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 232\u001b[0m, in \u001b[0;36mLabsheet.update_rows_by_id\u001b[1;34m(self, rows)\u001b[0m\n\u001b[0;32m    230\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows\u001b[39m\u001b[38;5;124m\"\u001b[39m: rows}; \u001b[38;5;28mprint\u001b[39m(payload)\n\u001b[0;32m    231\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_request(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mUPDATE_ROWS_BY_ID, payload)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_check(res, payload, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mUPDATE_ROWS_BY_ID)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccessfully updated rows.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "Cell \u001b[1;32mIn[3], line 133\u001b[0m, in \u001b[0;36mLabsheet.error_check\u001b[1;34m(self, res, payload, endpoint)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m APIException(\n\u001b[0;32m    126\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occured: \u001b[39m\u001b[38;5;124m\"\u001b[39m, endpoint, payload, res\n\u001b[0;32m    127\u001b[0m             )\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    130\u001b[0m             updated_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    131\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m updated_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    132\u001b[0m         ):\n\u001b[1;32m--> 133\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m APIException(\n\u001b[0;32m    134\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occured: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    135\u001b[0m                 endpoint,\n\u001b[0;32m    136\u001b[0m                 payload,\n\u001b[0;32m    137\u001b[0m                 res,\n\u001b[0;32m    138\u001b[0m             )\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m row:\n",
      "\u001b[1;31mAPIException\u001b[0m: An error occured: \nRequest: /labsheets/update-rows-by-id\n{\n  \"rows\": [\n    {\n      \"Run Name\": \"SET4REP1A4_TAL0000517\",\n      \"Column ID\": \"e03cfa54-0e6a-4280-83cc-5d6797d8d6dc\"\n    }\n  ],\n  \"apiKey\": \"************************************\",\n  \"manager\": \"MS Run\",\n  \"labsheet\": \"MS Run\"\n}\nResponse: [\n  {\n    \"ID\": \"SET4REP1A4_TAL0000517\",\n    \"updatedRows\": [\n      {\n        \"uuid\": \"99808d08-cbcc-4a28-bee4-914f646b775e\",\n        \"success\": \"true\"\n      },\n      {\n        \"uuid\": \"5b52caf0-7c3f-46cf-9977-535c75da78dc\",\n        \"success\": \"false\",\n        \"message\": \"the option 04398e98-8483-4695-8a0e-48b3ccadc84d is invalid\"\n      },\n      {\n        \"uuid\": \"d3603318-7e08-4825-b61d-471c547cd1de\",\n        \"success\": \"true\"\n      }\n    ]\n  }\n]\n"
     ]
    }
   ],
   "source": [
    "# MSR374 --> mass_spec_run_ids = [\"374\"]  this worked in sandbox...\n",
    "# Does not work in prod because Registry ID == MSR374 maps to Run Name == SET4REP1A4_TAL0000517 \n",
    "# and SET4REP1A4_TAL0000517 maps to multiple MSR\n",
    "\n",
    "column_id_list = [\"1\"]\n",
    "mass_spec_run_ids = [\"374\"]\n",
    "for cid, msr in zip(column_id_list, mass_spec_run_ids):\n",
    "    column_uuid = ls_msc.find_row(cid, id_type=\"barcode\")[\"rows\"][0][0]\n",
    "    mass_spec_run_name = ls_msr.find_row(msr, id_type=\"barcode\")[\"rows\"][0][2]\n",
    "    print(f\">>> Found column uuid => {column_uuid}\")\n",
    "    print(f\">>> Found mass spec Run Name => {mass_spec_run_name}\")\n",
    "    res = ls_msr.update_rows_by_id(\n",
    "        rows=[\n",
    "            {\n",
    "                #\"Registry ID\": msr,\n",
    "                \"Run Name\": mass_spec_run_name,\n",
    "                \"Column ID\": column_uuid,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Updated MSR -> {msr} with column -> {cid}\")\n",
    "    \n",
    "    \n",
    "##\n",
    "##\n",
    "## MS Runs labsheet updates are not possible, at least with the \"update_rows_by_id\" endpoint.\n",
    "## This is because for all of SET*REP1 samples, there are duplicate rows with the same Run Name\n",
    "## from having a DDA and a DIA run (sometimes, for SET1REP1, there's multiple DIA runs).\n",
    "## To backlink things in MS Runs Labsheet, I need to figure out how to use another endpoint \n",
    "## maybe update-rows-by-column-type (in the future... Right now, this feature is currently only \n",
    "## supported for BATCH_ID column type, so wouldn't work for Registry ID.\n",
    "##\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8cbcae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa02ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read in a CSV with all the mass spec runs\n",
    "manual_msr_dda = pd.read_csv('G:/My Drive/Lindsay Pino/proj/2023_scispot_utils/data/SET1 REP1 Non-scripted metadata for Scispot - S1R1 MS Run - DIA.csv')\n",
    "manual_msr_dda\n",
    "\n",
    "# get a list of all the MS Run registry IDs\n",
    "registry_ids = []\n",
    "for registry_id in manual_msr_dda['Registry ID']:\n",
    "    registry_id = re.sub(\"[^0-9]\", \"\", registry_id)\n",
    "    registry_ids.append(registry_id)\n",
    "\n",
    "# get a list of all the MS Run registry IDs\n",
    "digest_ids = []\n",
    "for digest_id in manual_msr_dda['Peptide Digest IDs']:\n",
    "    digest_id = re.sub(\"[^0-9]\", \"\", digest_id)\n",
    "    digest_ids.append(digest_id)\n",
    "\n",
    "# Example ->\n",
    "# lets add to the ms run sheet on id\n",
    "# MSR98\n",
    "# MSC1 <- column id 2\n",
    "# PDG197 <- protein digest id 197\n",
    "\n",
    "column_id_list = [\"1\"]*len(registry_ids)\n",
    "mass_spec_run_ids = registry_ids\n",
    "for cid, msr in zip(column_id_list, mass_spec_run_ids):\n",
    "    column_uuid = ls_msc.find_row(cid, id_type=\"barcode\")[\"rows\"][0][0]\n",
    "    print(f\">>> Found column uuid => {column_uuid}\")\n",
    "    res = ls_msr.update_rows_by_id(\n",
    "        rows=[\n",
    "            {\n",
    "                \"Registry ID\": msr,\n",
    "                \"Column ID\": column_uuid,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Updated MSR -> {msr} with column -> {cid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d15b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdgid, msr in zip(digest_ids, mass_spec_run_ids):\n",
    "    print(pdgid)\n",
    "    print(msr)\n",
    "    digest_uuid = ls_pdg.find_row(pdgid, id_type=\"barcode\")[\"rows\"][0][0]\n",
    "    print(f\">>> Found peptide digest uuid => {digest_uuid}\")\n",
    "    res = ls_msr.update_rows_by_id(\n",
    "        rows=[\n",
    "            {\n",
    "                \"Registry ID\": msr,\n",
    "                \"Peptide Digest IDs\": digest_uuid,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Updated mass spec run MSR -> {msr} with link to peptide digest PDG -> {pdgid}\")\n",
    "    \n",
    "# SET1 REP1 metadata sheet goes from PDG97-PDG288 with corresponding MSR1-MSR192\n",
    "# the sandbox has PDG1-PDG97 and MSR1-MSR193\n",
    "# so sandbox has all the MSR but only 1 of the corresponding PDG lol omg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf32abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gonna try to go back one more linkage and \"test\" these loops there...\n",
    "\n",
    "\n",
    "# read in a CSV with all the mass spec runs\n",
    "manual_pdg_nuc = pd.read_csv('G:/My Drive/Lindsay Pino/proj/2023_scispot_utils/data/SET1 REP1 Non-scripted metadata for Scispot - S1R1 Peptide Digest - Nucleoplasm TEST.csv')\n",
    "manual_pdg_nuc\n",
    "\n",
    "# get a list of all the MS Run registry IDs\n",
    "registry_ids = []\n",
    "for registry_id in manual_pdg_nuc['Registry ID']:\n",
    "    registry_id = re.sub(\"[^0-9]\", \"\", registry_id)\n",
    "    registry_ids.append(registry_id)\n",
    "\n",
    "# get a list of all the MS Run registry IDs\n",
    "fraction_ids = []\n",
    "for fraction_id in manual_pdg_nuc['Parent Sample']:\n",
    "    fraction_id = re.sub(\"[^0-9]\", \"\", fraction_id)\n",
    "    fraction_ids.append(fraction_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb4a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fraid, pdgid in zip(fraction_ids, registry_ids):\n",
    "    print(fraid)\n",
    "    print(pdgid)\n",
    "    fraction_uuid = ls_fra.find_row(fraid, id_type=\"barcode\")[\"rows\"][0][0]\n",
    "    print(f\">>> Found fraction uuid => {fraction_uuid}\")\n",
    "    res = ls_pdg.update_rows_by_id(\n",
    "        rows=[\n",
    "            {\n",
    "                \"Registry ID\": pdgid,\n",
    "                \"Parent Sample\": fraction_uuid,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Updated peptide digest PDG -> {pdgid} with protein fraction parent FRA -> {fraid}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
